{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GCC6cD8dgSiB"
   },
   "source": [
    "Importing and installing dependencies..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HzlLDhCZivbk"
   },
   "source": [
    "Upon research, I found a favourable approach to further pre-training was to perform further within-task or in-domain pretraining from the existing BERT model checkpoint.\n",
    "\n",
    "I've already collected around 150,000 tweets that are categorized as either hate speech, offensive or benign so this roughly satisfies the requirement that the pretraining data is within-task or in-domain.\n",
    "\n",
    "However there are far more tweet databases that can be used to further-pretrain my BERT model. There is a wealth of unsupervised tweet datasets online that I can make use of, these datasets often do not come in text form but rather the tweets are represented by their tweet IDs. Below I will describe the tweet datasets and retrieve their associated text using the tweepy module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RFfAGXRi6JXp"
   },
   "source": [
    "# Retrieving more pre-training data from unsupervised tweet datasets\n",
    "Using as wide a variety of sources as we can will increase the learning of our further-pretrained model. My goal when sourcing these datasets was to try and find tweet datasets which are largely user-generated, as hate speech online largely comes from user generated content.\n",
    "\n",
    "if I could find it, I would use tweet datasets likely to have aggressive or abusive content as well as possibly containing sexist and racial slurs. Even having some tweets just talking about racial, sex or homophobic issues would be beneficial for my model to be trained on as it may use the language associated with these issues.\n",
    "\n",
    "The following tweets can all be retireved by ID and they come from the following sources:\n",
    "\n",
    "\n",
    "*   <b>#UniteTheRight tweet database</b> - The Unite the Right rally (also known as the Charlottesville rally) was a protest in Charlottesville, Virginia, United States from August 11–12, 2017, to oppose the removal of a statue of Robert E. Lee in Emancipation Park, which itself was renamed from Lee Park two months earlier. Protesters included white supremacists, white nationalists, neo-Confederates, neo-Nazis, and militias. This dataset contains 200,113 tweet ids collected with the #unitetheright hashtag. The time ranges for the tweets are from 2017-08-04 11:44:12 to 2017-08-15 16:03:30 GMT.\n",
    "\n",
    "*   <b>Bill 10 Twitter IDs</b> - A list of 24876 Twitter IDs for tweets harvested between Nov. 28 and Dec. 6 2014 containing the hashtag #bill10. Bill 10 in the Alberta legislature would have given public and Catholic school boards the right to refuse student requests to form gay-straight alliances in schools. Under intense public interest it was withdrawn by the Conservative government.\n",
    "\n",
    "*   <b>BLMKidnapping</b> - These 136,990 tweet ids represent reaction to a Facebook Live video that was posted on January 3rd, 2017, showing four African American men violently attacking a white, mentally disabled man. The tweets were collected on 01/05/2017. After the video surfaced, the Twitter hashtag, #BLMkidnapping, was created and used to incorrectly attribute the violent attack to members of the Black Lives Matter movement. Police in Chicago, where the attack took place, have found no evidence the attack has any connection to the Black Lives Matter movement. This link is to a CNN story documenting the police denial of Black Lives Matter connection: http://www.cnn.com/2017/01/05/us/black-lives-matter-chicago-facebook-live-beating/index.html\n",
    "\n",
    "*   <b>#Charlottesville</b> - On Friday, August 11th, 2017 large groups of racist white nationalists carrying torches marched on the University of Virginia campus in Charlottesville, VA as an intimidation tactic against proponents for the removal of confederate statues of Robert E. Lee. The Friday evening march was held ahead of a much larger racist white nationalist rally in the center of Charlottesville planned for Saturday, August 12th, 2017. This dataset includes 100,000 tweet ids and it includes tweets posted from 01:13:56 - 7:11:36 EDT on August 12.\n",
    "\n",
    "*   <b>Replies to Ocasio-Cortez Tweets</b> - Replies to senator Rep. Alexandria Ocasio-Cortez’s Tweets and Retweets in March 2019. Whilst many tweets to Ms. Ocasio-Cortez may be glowing praise, I'm counting on a sizable portion of the tweets directed at her to be abusive and perhaps sexist and racist - I feel like this is a good enough hypothesis, owing to how toxic america's political climate has become.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lxQui5ILzVy4"
   },
   "source": [
    "Importing and Installing Dependencies ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Bucket: csc3002>]\n",
      "Requirement already satisfied: gcsfs in c:\\users\\fionn\\anaconda3\\lib\\site-packages (0.6.0)\n",
      "Requirement already satisfied: requests in c:\\users\\fionn\\anaconda3\\lib\\site-packages (from gcsfs) (2.22.0)\n",
      "Requirement already satisfied: google-auth>=1.2 in c:\\users\\fionn\\anaconda3\\lib\\site-packages (from gcsfs) (1.10.0)\n",
      "Requirement already satisfied: google-auth-oauthlib in c:\\users\\fionn\\anaconda3\\lib\\site-packages (from gcsfs) (0.4.1)\n",
      "Requirement already satisfied: decorator in c:\\users\\fionn\\anaconda3\\lib\\site-packages (from gcsfs) (4.4.1)\n",
      "Requirement already satisfied: fsspec>=0.6.0 in c:\\users\\fionn\\anaconda3\\lib\\site-packages (from gcsfs) (0.6.2)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\fionn\\anaconda3\\lib\\site-packages (from requests->gcsfs) (1.25.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\fionn\\anaconda3\\lib\\site-packages (from requests->gcsfs) (2019.11.28)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\fionn\\anaconda3\\lib\\site-packages (from requests->gcsfs) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\fionn\\anaconda3\\lib\\site-packages (from requests->gcsfs) (2.8)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in c:\\users\\fionn\\anaconda3\\lib\\site-packages (from google-auth>=1.2->gcsfs) (4.0)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in c:\\users\\fionn\\anaconda3\\lib\\site-packages (from google-auth>=1.2->gcsfs) (44.0.0.post20200106)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\fionn\\anaconda3\\lib\\site-packages (from google-auth>=1.2->gcsfs) (1.12.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\fionn\\anaconda3\\lib\\site-packages (from google-auth>=1.2->gcsfs) (3.1.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\fionn\\anaconda3\\lib\\site-packages (from google-auth>=1.2->gcsfs) (0.2.7)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\fionn\\anaconda3\\lib\\site-packages (from google-auth-oauthlib->gcsfs) (1.3.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\fionn\\anaconda3\\lib\\site-packages (from rsa<4.1,>=3.1.4->google-auth>=1.2->gcsfs) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\fionn\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import tweepy\n",
    "\n",
    "#Below is to authenticate google bucket access for local machines\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]= \"./storageCreds.json\"\n",
    "from google.cloud import storage\n",
    "storage_client = storage.Client()\n",
    "buckets = list(storage_client.list_buckets())\n",
    "print(buckets)\n",
    "\n",
    "#Below is for google colab environment\n",
    "\"\"\"from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "!gcloud config set project 'my-project-csc3002'\"\"\"\n",
    "\n",
    "!pip install gcsfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MWHejjMOAjYg"
   },
   "source": [
    "**Combining tweet ID dataframes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 21009,
     "status": "ok",
     "timestamp": 1578583098283,
     "user": {
      "displayName": "Fionn McConville",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDQ4Te6RRh1B7ENukR6-4xoNAaV2ajfGgNpCD6y=s64",
      "userId": "01326935138765014160"
     },
     "user_tz": 0
    },
    "id": "xyDNxFk8-5-B",
    "outputId": "2e086596-7012-4cfd-df8d-399cfdc8a1b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#UniteTheRight tweet database contains 200113 tweet IDs\n",
      "\n",
      "Bill 10 tweet database contains 24876 tweet IDs\n",
      "\n",
      "#blmkidnapping tweet database contains 136990 tweet IDs\n",
      "\n",
      "AOC tweet database contains 109201 tweet IDs\n"
     ]
    }
   ],
   "source": [
    "#UniteTheRight\n",
    "utr = 'gs://csc3002/pretrain_data/UniteTheRight.txt'\n",
    "utr = pd.read_csv(utr, sep=',',  index_col = False, encoding = 'utf-8', header = None, names = ['id'])\n",
    "print(\"#UniteTheRight tweet database contains\", len(utr.index), \"tweet IDs\")\n",
    "\n",
    "#Bill 10\n",
    "b10 = 'gs://csc3002/pretrain_data/bill10tweets.txt'\n",
    "b10 = pd.read_csv(b10, sep=',',  index_col = False, encoding = 'utf-8', header = None, names = ['id'])\n",
    "print(\"\\nBill 10 tweet database contains\", len(b10.index), \"tweet IDs\")\n",
    "\n",
    "#BlmKidnapping\n",
    "blm = 'gs://csc3002/pretrain_data/blmkidnapping_tweet_ids_v1.txt'\n",
    "blm = pd.read_csv(blm, sep=',',  index_col = False, encoding = 'utf-8', header = None, names = ['id'])\n",
    "print(\"\\n#blmkidnapping tweet database contains\", len(blm.index), \"tweet IDs\")\n",
    "\n",
    "#Ocasio-Cortez Replies\n",
    "aoc = 'gs://csc3002/pretrain_data/ocasio_cortez_replies.csv'\n",
    "aoc = pd.read_csv(aoc, sep=',',  index_col = False, encoding = 'utf-8', header = 0, names = ['id'])\n",
    "print(\"\\nAOC tweet database contains\", len(aoc.index), \"tweet IDs\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JGm50b8sEkVT"
   },
   "source": [
    "Now combining all of the tweet IDs into a single dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 22549,
     "status": "ok",
     "timestamp": 1578583099835,
     "user": {
      "displayName": "Fionn McConville",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDQ4Te6RRh1B7ENukR6-4xoNAaV2ajfGgNpCD6y=s64",
      "userId": "01326935138765014160"
     },
     "user_tz": 0
    },
    "id": "fnVTqEmJB8Rf",
    "outputId": "148b9a51-84db-4eac-b174-af2607913784"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 471180 tweet IDs in this dataset\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>896436979776143361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>896565219501232128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>897079831506153472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895836384468054017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896198992710717445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id\n",
       "0  896436979776143361\n",
       "1  896565219501232128\n",
       "2  897079831506153472\n",
       "3  895836384468054017\n",
       "4  896198992710717445"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full = pd.concat([aoc, blm, b10, utr], axis =0)\n",
    "full.drop_duplicates(subset='id',inplace =True ) #Important to drop duplicates\n",
    "\n",
    "#Shuffle Data\n",
    "full = full.sample(frac=1)\n",
    "full.reset_index(drop = True, inplace = True)\n",
    "\n",
    "print(\"There are\", len(full.index), \"tweet IDs in this dataset\")\n",
    "full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a tweepy method to obtain tweets via ID. Twitter API only allows us to extract tweets 100 at a time, as there are rate limits - therfore, we must set the wait_on_rate_limit parameter to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup_tweets(tweet_IDs, api):\n",
    "    \n",
    "    full_tweets = []\n",
    "    tweet_count = len(tweet_IDs)\n",
    "    \n",
    "    #Below code to monitor progress\n",
    "    x = int(tweet_count/5)\n",
    "    progress = {x: '20%', x*2: '40%', x*3: '60%', x*4: '80%'}\n",
    "    j = 0 # Remove mentions of j if i works to monitor progress\n",
    "    try:\n",
    "        for i in range((tweet_count // 100) + 1):\n",
    "            if j in list(progress.keys()):\n",
    "                print(progress[j], \"complete\")\n",
    "\n",
    "            # Catch the last group if it is less than 100 tweets\n",
    "            end_loc = min((i + 1) * 100, tweet_count)\n",
    "\n",
    "            full_tweets.extend(\n",
    "                api.statuses_lookup(id_=tweet_IDs[i * 100:end_loc], map_ = True))  \n",
    "            j = j+1\n",
    "            \n",
    "        return full_tweets\n",
    "    except tweepy.TweepError as e:\n",
    "        print(\"At Index:\", j, \"\\n\", e.reason)       \n",
    "        #Recursive call to continue even with exception\n",
    "        full_tweets + lookup_tweets(tweet_IDs[i+1:tweet_count], api)\n",
    "                \n",
    "\n",
    "#Google colab\n",
    "\"\"\"from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "with open('/content/drive/My Drive/twitter_credentials.json', \"r\") as f:\n",
    "  creds = json.load(f)\"\"\"\n",
    "\n",
    "#Local machine\n",
    "with open('./twitter_credentials.json', \"r\") as f:\n",
    "    creds = json.load(f)\n",
    "\n",
    "\n",
    "auth = tweepy.OAuthHandler(creds['CONSUMER_KEY'], creds['CONSUMER_SECRET'])\n",
    "auth.set_access_token(creds['ACCESS_TOKEN'], creds['ACCESS_SECRET'])\n",
    "\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True, \\\n",
    "                 retry_count=10, retry_delay=5, retry_errors=set([503])) # These last three params catch over-capacity error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4lwGD55n1imc"
   },
   "source": [
    "Applying the custom tweepy function to this dataframe to retrieve the text content corresponding to each tweet ID, then wrangling all of the text data into a singular dataframe.\n",
    "\n",
    "<b>The below cell may take a while to run.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 177\n",
      "Rate limit reached. Sleeping for: 137\n",
      "Rate limit reached. Sleeping for: 207\n",
      "Rate limit reached. Sleeping for: 29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 471180 entries, 0 to 471179\n",
      "Data columns (total 2 columns):\n",
      "id      471180 non-null int64\n",
      "text    235551 non-null object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 7.2+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1108908334445322241</td>\n",
       "      <td>@AOC Says the bartender...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1102941794491351040</td>\n",
       "      <td>@AOC @bungarsargon Right now all you are doing is hurting our own party with division. Why can you just acknowledge… https://t.co/OYpLKjt6bM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>896445976617132032</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1111591492567613440</td>\n",
       "      <td>@dustbusterz @hmcghee @AOC @MSNBC Flopped as in her pushing her green new deal.  But nuance takes some thought</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>540340474972626944</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id  \\\n",
       "0  1108908334445322241   \n",
       "1  1102941794491351040   \n",
       "2  896445976617132032    \n",
       "3  1111591492567613440   \n",
       "4  540340474972626944    \n",
       "\n",
       "                                                                                                                                           text  \n",
       "0  @AOC Says the bartender...                                                                                                                    \n",
       "1  @AOC @bungarsargon Right now all you are doing is hurting our own party with division. Why can you just acknowledge… https://t.co/OYpLKjt6bM  \n",
       "2  NaN                                                                                                                                           \n",
       "3  @dustbusterz @hmcghee @AOC @MSNBC Flopped as in her pushing her green new deal.  But nuance takes some thought                                \n",
       "4  NaN                                                                                                                                           "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_ids = list(full['id'])\n",
    "\n",
    "#Below works as long as it's not a multiple of 100. takes a while\n",
    "results = lookup_tweets(tweet_ids, api)\n",
    "                                  \n",
    "temp = json.dumps([status._json for status in results]) #create JSON\n",
    "final = pd.read_json(temp, orient='records')\n",
    "final = final[['id','text']]\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "print(final.info())\n",
    "final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It'll be interesting to see if the amount of NaNs is the result of an error in my code, the database or if it's just banned accounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 2 columns):\n",
      "id      1000 non-null int64\n",
      "text    515 non-null object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 15.8+ KB\n",
      "None\n",
      "User has been suspended.                                                                                                                         204\n",
      "Sorry, you are not authorized to see this status.                                                                                                28 \n",
      "RT @AynRandPaulRyan: David Duke in #Charlottesville saying this Nazi, #UniteTheRight fiasco \"fulfills the promises of Donald Trump.\" \\nhttps…    24 \n",
      "RT @RealAlexRubi: Massive brawl breaks out, tiki torches thrown as #UniteTheRight reaches Jefferson monument in #Charlottesville. Chemicals…     7  \n",
      "RT @RVAwonk: Here's former KKK leader David Duke explicitly stating that Trump motivated the white supremacist #UniteTheRight rally in #Cha…     7  \n",
      "RT @PrisonPlanet: Tucker is the only national mainstream reporter to cover this. https://t.co/gNaBrifiLm #BLMKidnapping https://t.co/223ire…     6  \n",
      "RT @JDeanSeal: This is the car that plowed through a crowd at the #UniteTheRight rally. Stopped along Monticello Ave. https://t.co/7Uf4lHfA…     5  \n",
      "RT @scrowder: YouTube removed video of the #BLMKidnapping. Because of course. https://t.co/dCJ1XwgrXy                                            4  \n",
      "RT @tomperriello: The rally was instigated and then planned for three months by one side only. They dubbed it #UniteTheRight. Trump blames…      4  \n",
      "Name: text, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>896630257977085952</td>\n",
       "      <td>User has been suspended.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>896375834415697920</td>\n",
       "      <td>User has been suspended.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>897199189775527939</td>\n",
       "      <td>User has been suspended.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>816865867371679744</td>\n",
       "      <td>RT @MattWalshBlog: Will @deray and @ShaunKing apologize for fomenting the kind of racial hate that led to the #BLMKidnapping?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1103074785859297280</td>\n",
       "      <td>User has been suspended.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>893978535081201668</td>\n",
       "      <td>User has been suspended.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1111105464744493056</td>\n",
       "      <td>@AOC This is not infrastructure @AOC  this is building maintenance.  \\n\\nInfrastructure is roads, airports, bridges..… https://t.co/hMqbzbc0Z4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>896476851572310016</td>\n",
       "      <td>RT @AynRandPaulRyan: David Duke in #Charlottesville saying this Nazi, #UniteTheRight fiasco \"fulfills the promises of Donald Trump.\" \\nhttps…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1107334308451237888</td>\n",
       "      <td>@my_surreality @JoeySalads @AOC Lol this guy... https://t.co/SlsnzlerQc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>540531308183572480</td>\n",
       "      <td>RT @mikesbloggity: If you want to send an email to your MLA about #Bill10. Visit: http://t.co/C7onNIA7HH It takes less than ten seconds.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>816813213128032256</td>\n",
       "      <td>No status found with that ID.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1105213583573614592</td>\n",
       "      <td>@sctadsen @Charlie35170590 @AOC He didn’t judge people by the color of their skin but their character.  This is 100… https://t.co/eS7Tyhkgxr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>896426601268695042</td>\n",
       "      <td>Who could have foreseen the #UniteTheRight white nationalist resurgence?\\nAlmost as if someone emboldened them....… https://t.co/5dSdZzhjzj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>897102256528642048</td>\n",
       "      <td>#SmartDissent #ThisIsNotUs #ThisIsNotMyAmerica #Resist #TrumpsAmerica #TrumpsNazis #UniteTheRight #AltRight… https://t.co/3Rj7ygZHZB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>816841554539245568</td>\n",
       "      <td>No status found with that ID.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1108929550438686727</td>\n",
       "      <td>@AOC Many of us did not get to experience the prosperous 90s...mostly because Bill Clinton cut welfare programs and… https://t.co/5gNPs2MMJd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>896382844930600960</td>\n",
       "      <td>No status found with that ID.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>896565758205059072</td>\n",
       "      <td>No status found with that ID.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>896833545120997376</td>\n",
       "      <td>RT @NBC29: MORE: While attempting to hold a press conference, #UniteTheRight organizer, Jason Kessler gets swarmed and punched in the face.…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1101545728072019968</td>\n",
       "      <td>@AOC You mean pump your people so they can leave and go on CNN and get private sector jobs or run someplace else. T… https://t.co/o5N5W1nRix</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id  \\\n",
       "0   896630257977085952    \n",
       "1   896375834415697920    \n",
       "2   897199189775527939    \n",
       "3   816865867371679744    \n",
       "4   1103074785859297280   \n",
       "5   893978535081201668    \n",
       "6   1111105464744493056   \n",
       "7   896476851572310016    \n",
       "8   1107334308451237888   \n",
       "9   540531308183572480    \n",
       "10  816813213128032256    \n",
       "11  1105213583573614592   \n",
       "12  896426601268695042    \n",
       "13  897102256528642048    \n",
       "14  816841554539245568    \n",
       "15  1108929550438686727   \n",
       "16  896382844930600960    \n",
       "17  896565758205059072    \n",
       "18  896833545120997376    \n",
       "19  1101545728072019968   \n",
       "\n",
       "                                                                                                                                              text  \n",
       "0   User has been suspended.                                                                                                                        \n",
       "1   User has been suspended.                                                                                                                        \n",
       "2   User has been suspended.                                                                                                                        \n",
       "3   RT @MattWalshBlog: Will @deray and @ShaunKing apologize for fomenting the kind of racial hate that led to the #BLMKidnapping?                   \n",
       "4   User has been suspended.                                                                                                                        \n",
       "5   User has been suspended.                                                                                                                        \n",
       "6   @AOC This is not infrastructure @AOC  this is building maintenance.  \\n\\nInfrastructure is roads, airports, bridges..… https://t.co/hMqbzbc0Z4  \n",
       "7   RT @AynRandPaulRyan: David Duke in #Charlottesville saying this Nazi, #UniteTheRight fiasco \"fulfills the promises of Donald Trump.\" \\nhttps…   \n",
       "8   @my_surreality @JoeySalads @AOC Lol this guy... https://t.co/SlsnzlerQc                                                                         \n",
       "9   RT @mikesbloggity: If you want to send an email to your MLA about #Bill10. Visit: http://t.co/C7onNIA7HH It takes less than ten seconds.        \n",
       "10  No status found with that ID.                                                                                                                   \n",
       "11  @sctadsen @Charlie35170590 @AOC He didn’t judge people by the color of their skin but their character.  This is 100… https://t.co/eS7Tyhkgxr    \n",
       "12  Who could have foreseen the #UniteTheRight white nationalist resurgence?\\nAlmost as if someone emboldened them....… https://t.co/5dSdZzhjzj     \n",
       "13  #SmartDissent #ThisIsNotUs #ThisIsNotMyAmerica #Resist #TrumpsAmerica #TrumpsNazis #UniteTheRight #AltRight… https://t.co/3Rj7ygZHZB            \n",
       "14  No status found with that ID.                                                                                                                   \n",
       "15  @AOC Many of us did not get to experience the prosperous 90s...mostly because Bill Clinton cut welfare programs and… https://t.co/5gNPs2MMJd    \n",
       "16  No status found with that ID.                                                                                                                   \n",
       "17  No status found with that ID.                                                                                                                   \n",
       "18  RT @NBC29: MORE: While attempting to hold a press conference, #UniteTheRight organizer, Jason Kessler gets swarmed and punched in the face.…    \n",
       "19  @AOC You mean pump your people so they can leave and go on CNN and get private sector jobs or run someplace else. T… https://t.co/o5N5W1nRix    "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Quick function to beautify the error message\n",
    "def getExceptionMessage(msg):\n",
    "    words = msg.split(' ')\n",
    "\n",
    "    errorMsg = \"\"\n",
    "    for index, word in enumerate(words):\n",
    "        if index not in [0,1,2]:\n",
    "            errorMsg = errorMsg + ' ' + word\n",
    "    errorMsg = errorMsg.rstrip(\"\\'}]\")\n",
    "    errorMsg = errorMsg.lstrip(\" \\'\")\n",
    "\n",
    "    return errorMsg\n",
    "\n",
    "def getErrorDesc(df): \n",
    "    for row in range(0, len(df.index)):\n",
    "        current = df.loc[row]\n",
    "        if pd.isna(current.text) == True:  \n",
    "            try:    \n",
    "                twt = api.get_status(current.id)\n",
    "            except tweepy.TweepError as err:\n",
    "                df.loc[row, 'text'] = getExceptionMessage(err.reason)\n",
    "    return df\n",
    "\n",
    "#If I attempt this with the whole dataset it'll take ages,\n",
    "#So I'll just randomly sample the dataset to get a rough idea\n",
    "df = final.sample(1000)\n",
    "df.reset_index(drop = True, inplace = True)\n",
    "print(df.info())\n",
    "df = getErrorDesc(df)\n",
    "print(\"\\n\", df.text.value_counts()[1:10])\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting that not only has our function above showcased the errors associated, but also it's shown that there are many duplicate tweets as the result of RTs. We can remove this through the drop duplicates method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text must be preprocessed before it becomes it is exported to a csv, otherwise it throws an error. The error is caused by the function not being able to encode unicode characters such as emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The contraction mapping below is not perfect. There are many ambigious contractions\n",
    "#which are impossible to definitively resolve (e.g. he's - he has or he is).\n",
    "#The mappings below are unambigious but they are mapped to the most likely contractions\n",
    "#We specifically choose flashtext as our library of choice for text replacement purposes\n",
    "#because of it’s execution speed.\n",
    "contractions = { \n",
    "\"ain't\": \"is not\",\"aren't\": \"are not\", \"can't\": \"cannot\", \"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\"cause\": \"because\",\"could've\": \"could have\",\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\"didn't\": \"did not\",\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\"hadn't\": \"had not\",\"hadn't've\": \"had not have\",\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\", \"he'd\": \"he would\",\"he'd've\": \"he would have\", \"he'll\": \"he will\",\n",
    "\"he'll've\": \"he will have\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'll\": \"how will\",\n",
    "\"how's\": \"how is \", \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\",\n",
    "\"I'll've\": \"I will have\",\"I'm\": \"I am\",\"I've\": \"I have\",\"isn't\": \"is not\",\n",
    "\"it'd\": \"it had\", \"it'd've\": \"it would have\",\"it'll\": \"it will\", \"it'll've\": \"it will have\",\n",
    "\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\",\n",
    "\"must've\": \"must have\", \"mustn't\": \"must not\",\"mustn't've\": \"must not have\",\n",
    "\"needn't\": \"need not\", \"needn't've\": \"need not have\",\"oughtn't\": \"ought not\",\n",
    "\"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\",\"sha'n't\": \"shall not\",\n",
    "\"shan't've\": \"shall not have\",\"she'd\": \"she had\",\"she'd've\": \"she would have\",\n",
    "\"she'll\": \"she will\", \"she'll've\": \"she will have\",\"she's\": \"she is\",\n",
    "\"should've\": \"should have\",\"shouldn't\": \"should not\",\"shouldn't've\": \"should not have\",\n",
    "\"so've\": \"so have\",\"so's\": \"so is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\",\n",
    "\"that's\": \"that is\", \"there'd\": \"there had\",\"there'd've\": \"there would have\",\n",
    "\"there's\": \"there is\",\"they'd\": \"they had\", \"they'd've\": \"they would have\",\n",
    "\"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\",\n",
    "\"they've\": \"they have\", \"to've\": \"to have\",\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we would\",\"we'd've\": \"we would have\",\"we'll\": \"we will\",\"we'll've\": \"we will have\",\n",
    "\"we're\": \"we are\",\"we've\": \"we have\",\"weren't\": \"were not\",\"what'll\": \"what will\",\n",
    "\"what'll've\": \"what will have\",\"what're\": \"what are\",\"what's\": \"what is\",\n",
    "\"what've\": \"what have\",\"when's\": \"when is\",\"when've\": \"when have\",\"where'd\": \"where did\",\n",
    "\"where's\": \"where has\",\"where've\": \"where have\",\"who'll\": \"who will\",\n",
    "\"who'll've\": \"who will have\",\"who's\": \"who is\",\"who've\": \"who have\",\"why's\": \"why is\",\n",
    "\"why've\": \"why have\",\"will've\": \"will have\",\"won't\": \"will not\",\"won't've\": \"will not have\",\n",
    "\"would've\": \"would have\",\"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\",\n",
    "\"y'all\": \"you all\",\"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\n",
    "\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\",\n",
    "\"you'd've\": \"you would have\",\"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "\"you're\": \"you are\", \"you've\": \"you have\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text_string):\n",
    "    \"\"\"\n",
    "    Accepts a text string and:\n",
    "    1) Removes URLS\n",
    "    2) lots of whitespace with one instance\n",
    "    3) Removes mentions\n",
    "    4) Uses the html.unescape() method to convert unicode to text counterpart\n",
    "    5) Replace & with and\n",
    "    6) Remove the fact the tweet is a retweet if it is - knowing the tweet is \n",
    "       a retweet does not help towards our classification task.\n",
    "    This allows us to get standardized counts of urls and mentions\n",
    "    Without caring about specific people mentioned\n",
    "    \"\"\"\n",
    "    space_pattern = '\\s+'\n",
    "    giant_url_regex = ('http[s]?://(?:[a-zA-Z]|[0-9]|[#$-_@.&+]|'\n",
    "        '[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "    mention_regex = '@[\\w\\-]+:'\n",
    "    mention_regex1 = '@[\\w\\-]+'\n",
    "    RT_regex = '(RT|rt)[ ]*@[ ]*[\\S]+'\n",
    "    \n",
    "    # Replaces urls with URL\n",
    "    parsed_text = re.sub(giant_url_regex, '', text_string)\n",
    "    parsed_text = re.sub('URL', '', parsed_text)\n",
    "    \n",
    "    # Remove the fact the tweet is a retweet. \n",
    "    # (we're only interested in the language of the tweet here)\n",
    "    parsed_text = re.sub(RT_regex, ' ', parsed_text) \n",
    "    \n",
    "    # Removes mentions as they're redundant information\n",
    "    parsed_text = re.sub(mention_regex, '',  parsed_text)\n",
    "    #including ones with semi-colons after - this seems to come up often\n",
    "    parsed_text = re.sub(mention_regex1, '',  parsed_text)  \n",
    "\n",
    "    #Remove unicode\n",
    "    parsed_text = re.sub(r'[^\\x00-\\x7F]','', parsed_text) \n",
    "    parsed_text = re.sub(r'&#[0-9]+;', '', parsed_text)  \n",
    "\n",
    "    # Convert unicode missed by regex to text\n",
    "   #parsed_text = html.unescape(parsed_text)\n",
    "\n",
    "    #Remove excess whitespace at the end\n",
    "    parsed_text = re.sub(space_pattern, ' ', parsed_text) \n",
    "    \n",
    "    #Set text to lowercase and strip\n",
    "    parsed_text = parsed_text.lower()\n",
    "    parsed_text = parsed_text.strip()\n",
    "    \n",
    "    return parsed_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rxd_Pr1_FtG0"
   },
   "source": [
    "Now concatenating the charlottesville dataset which already has the tweets associated with each ID so no text retrieval function via tweepy is necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nullvals = final.text.isna().sum()\n",
    "print(\"Amount of tweets IDs not returning text:\", nullvals)\n",
    "per = (nullvals/len(final.index)) * 100\n",
    "print((\"Which is %.2f%% of the overall dataset\") % (per))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>235546</th>\n",
       "      <td>896201447838187520</td>\n",
       "      <td>happening now at uva. our people on the march. will you be at #unitetheright tomorrow?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235547</th>\n",
       "      <td>896835566624546816</td>\n",
       "      <td>jason kessler organized the #unitetheright rally. he deserves the shaming for organizing &amp;amp; the violence it incited. https</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235548</th>\n",
       "      <td>1102729934894653440</td>\n",
       "      <td>i 2nd that shout out!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235549</th>\n",
       "      <td>1103276581060005889</td>\n",
       "      <td>perhaps it is just a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235550</th>\n",
       "      <td>896247350808784896</td>\n",
       "      <td>alt right #unitetheright woman tells #antifa counter-protester that he \"sounds like a n-----\" #charlottesville</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id  \\\n",
       "235546  896201447838187520    \n",
       "235547  896835566624546816    \n",
       "235548  1102729934894653440   \n",
       "235549  1103276581060005889   \n",
       "235550  896247350808784896    \n",
       "\n",
       "                                                                                                                                 text  \n",
       "235546  happening now at uva. our people on the march. will you be at #unitetheright tomorrow?                                         \n",
       "235547  jason kessler organized the #unitetheright rally. he deserves the shaming for organizing &amp; the violence it incited. https  \n",
       "235548  i 2nd that shout out!                                                                                                          \n",
       "235549  perhaps it is just a                                                                                                           \n",
       "235550  alt right #unitetheright woman tells #antifa counter-protester that he \"sounds like a n-----\" #charlottesville                 "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.dropna(inplace = True)\n",
    "final.reset_index(drop=True, inplace = True)\n",
    "final['text'] = final['text'].apply(preprocess)\n",
    "\n",
    "#Interim save\n",
    "final.to_csv('gs://csc3002/Raw_Data/idstext.csv', sep = ',', encoding='utf-8', \\\n",
    "                 index = False, header = True)\n",
    "final.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A5h7AM7hAhii"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#Charlottesville tweet database contains 200000 tweet IDs\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 200000 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      "id      200000 non-null int64\n",
      "text    200000 non-null object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 4.6+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>897661668787982336</td>\n",
       "      <td>It's almost as if people are exactly who they say they are https://t.co/MnWFXZd9c3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>897654901534228480</td>\n",
       "      <td>@Slate Conservative media: Yes, Trump's response to Charlottesville was bad, but what about Obama? https://t.co/jjINXL5Qp0 via @slate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>897659748597870592</td>\n",
       "      <td>👀 https://t.co/qeyzYeblwu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>897660496656179202</td>\n",
       "      <td>😂 😂 😂 Karma really isn't wasting time.. https://t.co/JYRqf6vlSX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>897642311903055872</td>\n",
       "      <td>After Charlottesville, Black Lives Matter Issues New Demand - https://t.co/Vuw3IvrhL2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id  \\\n",
       "0  897661668787982336   \n",
       "1  897654901534228480   \n",
       "2  897659748597870592   \n",
       "3  897660496656179202   \n",
       "4  897642311903055872   \n",
       "\n",
       "                                                                                                                                    text  \n",
       "0  It's almost as if people are exactly who they say they are https://t.co/MnWFXZd9c3                                                     \n",
       "1  @Slate Conservative media: Yes, Trump's response to Charlottesville was bad, but what about Obama? https://t.co/jjINXL5Qp0 via @slate  \n",
       "2  👀 https://t.co/qeyzYeblwu                                                                                                              \n",
       "3  😂 😂 😂 Karma really isn't wasting time.. https://t.co/JYRqf6vlSX                                                                        \n",
       "4  After Charlottesville, Black Lives Matter Issues New Demand - https://t.co/Vuw3IvrhL2                                                  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Charlottesville - Contains full text in columns\n",
    "charl = 'gs://csc3002/pretrain_data/charlottesville_aug15_sample.csv'\n",
    "charl = pd.read_csv(charl, sep=',',  index_col = False, encoding = 'utf-8', header = 0,)\n",
    "charl1 = 'gs://csc3002/pretrain_data/aug16_sample.csv'\n",
    "charl1 = pd.read_csv(charl1, sep=',',  index_col = False, encoding = 'utf-8', header = 0,)\n",
    "charl2 = 'gs://csc3002/pretrain_data/aug17_sample.csv'\n",
    "charl2 = pd.read_csv(charl2, sep=',',  index_col = False, encoding = 'utf-8', header = 0,)\n",
    "charl3 = 'gs://csc3002/pretrain_data/aug18_sample.csv'\n",
    "charl3 = pd.read_csv(charl3, sep=',',  index_col = False, encoding = 'utf-8', header = 0,)\n",
    "\n",
    "dfs = [charl[['id','full_text']], charl1[['id','full_text']], \\\n",
    "       charl2[['id','full_text']], charl3[['id','full_text']]]\n",
    "       \n",
    "charlot = pd.concat(dfs, axis = 0)\n",
    "charlot.rename(columns = {'full_text':'text'}, inplace = True)\n",
    "print(\"\\n#Charlottesville tweet database contains\", len(charlot.index), \"tweet IDs\")\n",
    "\n",
    "print(charlot.info())\n",
    "charlot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WPLroE4l3hGU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 435551 entries, 0 to 435550\n",
      "Data columns (total 2 columns):\n",
      "id      435551 non-null int64\n",
      "text    435551 non-null object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 6.6+ MB\n"
     ]
    }
   ],
   "source": [
    "final1 = pd.concat([final, charlot], axis = 0)\n",
    "final1 = final1.sample(frac=1) #shuffle\n",
    "final1['text'] = final1['text'].apply(preprocess)\n",
    "final1.reset_index(drop = True, inplace = True)\n",
    "final1.to_csv('gs://csc3002/pretrain_data/full.csv', sep = ',', encoding='utf-8', \\\n",
    "                 index = False, header = True)\n",
    "final1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "RetrievingPretrainingData.ipynb",
   "provenance": [
    {
     "file_id": "1iLhgDQ5aFlrLqyx5772zA2zYmFs5BNn0",
     "timestamp": 1578581115316
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
