{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding tokens to vocab file to represent emojis\n",
    "\n",
    "We create a function which reads in the most common ~1500 emojis in real time, (kindly provided by the website http://www.emojistats.org/) and stores them as a dataframe. We do this by saving the website as a html file, then parsing it using BeautifulSoup.\n",
    "\n",
    "We also add in the mult keyword at the start of the most common 500 of these so that we can have representations for when there are multiple occurences of these emojis in a row.\n",
    "\n",
    "This will create a dataframe where we have the most common emojis and their 'mult' counterpart, we can store these tokens in our vocab file for BERT where they will all have randomly initialized weights at the initial BERT checkpoint. These weights will be updated in fne-tuning and perhaps we will obtain intelligent contextual information this way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: demoji==0.1.5 from file:///C:/Users/fionn/Documents/CSC3002_Project/CSC3002_Detecting_Hate_Speech_On_Social_Media/csc3002_detecting_hate_speech/Text_Preprocessing/demoji-0.1.5-py3-none-any.whl in c:\\users\\fionn\\anaconda3\\lib\\site-packages (0.1.5)\n",
      "Requirement already satisfied: requests<3.0.0 in c:\\users\\fionn\\anaconda3\\lib\\site-packages (from demoji==0.1.5) (2.22.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\fionn\\anaconda3\\lib\\site-packages (from demoji==0.1.5) (44.0.0.post20200106)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\fionn\\anaconda3\\lib\\site-packages (from requests<3.0.0->demoji==0.1.5) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\fionn\\anaconda3\\lib\\site-packages (from requests<3.0.0->demoji==0.1.5) (1.25.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\fionn\\anaconda3\\lib\\site-packages (from requests<3.0.0->demoji==0.1.5) (2019.11.28)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\fionn\\anaconda3\\lib\\site-packages (from requests<3.0.0->demoji==0.1.5) (3.0.4)\n",
      "\u001b[33mDownloading emoji data ...\u001b[0m\n",
      "\u001b[92m... OK\u001b[0m (Got response in 1.01 seconds)\n",
      "\u001b[92m... OK\u001b[0m (Got response in 0.86 seconds)\n",
      "Requirement already satisfied: demoji==0.1.5 from file:///C:/Users/fionn/Documents/CSC3002_Project/CSC3002_Detecting_Hate_Speech_On_Social_Media/csc3002_detecting_hate_speech/demoji-0.1.5-py3-none-any.whl in c:\\users\\fionn\\anaconda3\\lib\\site-packages (0.1.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\fionn\\anaconda3\\lib\\site-packages (from demoji==0.1.5) (44.0.0.post20200106)\n",
      "Requirement already satisfied: requests<3.0.0 in c:\\users\\fionn\\anaconda3\\lib\\site-packages (from demoji==0.1.5) (2.22.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\fionn\\anaconda3\\lib\\site-packages (from requests<3.0.0->demoji==0.1.5) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\fionn\\anaconda3\\lib\\site-packages (from requests<3.0.0->demoji==0.1.5) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\fionn\\anaconda3\\lib\\site-packages (from requests<3.0.0->demoji==0.1.5) (1.25.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\fionn\\anaconda3\\lib\\site-packages (from requests<3.0.0->demoji==0.1.5) (2019.11.28)\n",
      "\u001b[33mDownloading emoji data ...\u001b[0m\n",
      "\u001b[92m... OK\u001b[0m (Got response in 1.41 seconds)\n",
      "\u001b[33mWriting emoji data to C:\\Users\\fionn\\.demoji/codes.json ...\u001b[0m\n",
      "\u001b[92m... OK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from bs4 import BeautifulSoup as BSHTML\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "#Wheel file below is in path\n",
    "!pip install demoji-0.1.5-py3-none-any.whl\n",
    "import demoji\n",
    "demoji.download_codes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FILE = 'Emoji Stats - Realtime Emoji Use on iOS.html'\n",
    "OUTPUT_FILE = 'emojiCounts.csv'\n",
    "\n",
    "f = open(OUTPUT_FILE,'w')\n",
    "f.write('emoji,count\\n') # write headers\n",
    "\n",
    "with open(INPUT_FILE) as texts:\n",
    "    soup = BSHTML(texts)\n",
    "    lis = soup.findAll('ul', attrs = {'class' : 'emojilist'})\n",
    "    for li in lis:\n",
    "        emjList = li.find_all('span')\n",
    "        for i, _ in enumerate(emjList):\n",
    "            emoji = emjList[i]['id'].replace('value_', '')\n",
    "            emoji = emoji.replace('_', ' ')\n",
    "            count = emjList[i].next\n",
    "            count = count.replace (',', '')\n",
    "            f.write(emoji+','+count+'\\n') # write to file\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're trying to create token representations that are identical to our `emojiReplace_v2` function, demonstrated below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      " No seriously. It has ðŸ˜‚ðŸ¤£ https://t.co/4k4jlLTDUj\n",
      "\n",
      "Replacing Emojis:\n",
      " No seriously. It has facexwithxtearsxofxjoy rollingxonxthexfloorxlaughing  https://t.co/4k4jlLTDUj\n",
      "\n",
      "\n",
      "Original:\n",
      " Same. We really are soulmates... Dumb AF but soulmates nonetheless ðŸ™ƒðŸ™ƒðŸ™ƒðŸ™ƒðŸ™ƒðŸ™ƒðŸ™ƒðŸ™ƒðŸ™ƒðŸ™ƒðŸ™ƒðŸ™ƒðŸ™ƒðŸ™ƒ https://t.co/ZwXTny02jj\n",
      "\n",
      "Replacing emojis:\n",
      " Same. We really are soulmates... Dumb AF but soulmates nonetheless multupsidexdownxface   https://t.co/ZwXTny02jj\n"
     ]
    }
   ],
   "source": [
    "def emojiReplace_v2(text_string):\n",
    "    emoji_dict = demoji.findall(text_string)    \n",
    "    for emoji in emoji_dict.keys():\n",
    "        #Making the connecting token between words a normal letter 'w' because BERT's tokenizer\n",
    "        #splits on special tokens like '%' and '$'\n",
    "        emoji_token = 'x'.join(re.split('\\W+', emoji_dict[emoji])) + ' '\n",
    "        text_string = text_string.replace(emoji, emoji_token)\n",
    "        \n",
    "        #Controlling for multiple emojis in a row\n",
    "        pattern = '(' + emoji_token + ')' + '{2,}'\n",
    "        text_string = re.sub(pattern, 'mult' + emoji_token + ' ', text_string)\n",
    "    return text_string\n",
    "\n",
    "#Load in HatEval data\n",
    "df = pd.read_csv('../Raw_Data/hateval2019/hateval2019_en_train.csv', sep=',',  index_col = False, encoding = 'utf-8')\n",
    "df = pd.read_csv('Raw_Data/hateval2019/hateval2019_en_train.csv', sep=',',  index_col = False, encoding = 'utf-8')\n",
    "df.rename(columns={'text': 'tweet', 'HS': 'label'}, inplace=True)\n",
    "\n",
    "testtweet = df['tweet'][300]\n",
    "\n",
    "print(\"Original:\\n\", testtweet)\n",
    "print(\"\\nReplacing Emojis:\\n\", emojiReplace_v2(testtweet))\n",
    "\n",
    "testtweet1 = df['tweet'][7436]\n",
    "\n",
    "print(\"\\n\\nOriginal:\\n\", testtweet1)\n",
    "print(\"\\nReplacing emojis:\\n\", emojiReplace_v2(testtweet1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting emoji descriptions to the token representation we will crete in emojiReplace_v2\n",
    "def makeToken(text):\n",
    "    text = 'x'.join(re.split('\\W+', text))\n",
    "    return text\n",
    "\n",
    "#Add 'mult' to most popular 500 emojis so we have token representation\n",
    "#for consecutive emojis as well as individual ones\n",
    "def addMult(text):\n",
    "    text = 'mult' + text\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emoji</th>\n",
       "      <th>count</th>\n",
       "      <th>tokens</th>\n",
       "      <th>mult</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>face with tears of joy</td>\n",
       "      <td>332059305</td>\n",
       "      <td>facexwithxtearsxofxjoy</td>\n",
       "      <td>multfacexwithxtearsxofxjoy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>heavy black heart</td>\n",
       "      <td>171566133</td>\n",
       "      <td>heavyxblackxheart</td>\n",
       "      <td>multheavyxblackxheart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>face throwing a kiss</td>\n",
       "      <td>122353058</td>\n",
       "      <td>facexthrowingxaxkiss</td>\n",
       "      <td>multfacexthrowingxaxkiss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>smiling face with heart shaped eyes</td>\n",
       "      <td>87122195</td>\n",
       "      <td>smilingxfacexwithxheartxshapedxeyes</td>\n",
       "      <td>multsmilingxfacexwithxheartxshapedxeyes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rolling on the floor laughing</td>\n",
       "      <td>52003805</td>\n",
       "      <td>rollingxonxthexfloorxlaughing</td>\n",
       "      <td>multrollingxonxthexfloorxlaughing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 emoji      count  \\\n",
       "0               face with tears of joy  332059305   \n",
       "1                    heavy black heart  171566133   \n",
       "2                 face throwing a kiss  122353058   \n",
       "3  smiling face with heart shaped eyes   87122195   \n",
       "4        rolling on the floor laughing   52003805   \n",
       "\n",
       "                                tokens  \\\n",
       "0               facexwithxtearsxofxjoy   \n",
       "1                    heavyxblackxheart   \n",
       "2                 facexthrowingxaxkiss   \n",
       "3  smilingxfacexwithxheartxshapedxeyes   \n",
       "4        rollingxonxthexfloorxlaughing   \n",
       "\n",
       "                                      mult  \n",
       "0               multfacexwithxtearsxofxjoy  \n",
       "1                    multheavyxblackxheart  \n",
       "2                 multfacexthrowingxaxkiss  \n",
       "3  multsmilingxfacexwithxheartxshapedxeyes  \n",
       "4        multrollingxonxthexfloorxlaughing  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read in csv created in 2nd cell and sort\n",
    "emojiCounts = pd.read_csv(OUTPUT_FILE, sep = ',', header = 0) \n",
    "emojiCounts.sort_values('count', inplace = True, ascending = False)\n",
    "\n",
    "emojiCounts['tokens'] = emojiCounts['emoji'].apply(makeToken)\n",
    "\n",
    "emojiCounts['mult'] = emojiCounts['tokens'][0:500].apply(addMult)\n",
    "\n",
    "emojiCounts.to_csv('emojiCounts.csv', sep = ',', index = False)\n",
    "emojiCounts.reset_index(inplace = True, drop = True)\n",
    "emojiCounts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create new vocab file with additional emoji representations. Hopefully these emoji tokens can become weighted after fine-tuning and have a positive effect on our performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vocab.txt', encoding='utf-8', errors='ignore') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "for i in range(1,100):\n",
    "    lines[i] = emojiCounts['tokens'][i-1] + '\\n'\n",
    "    \n",
    "#Tokens 100, 101, 102 and 103 are the VITAL [UNK], [CLS], [SEP] and [MASK] tokens respectively.\n",
    "#We must skip these lines\n",
    "for i in range(104, 500):\n",
    "    lines[i] = emojiCounts['tokens'][i-3] + '\\n'\n",
    "    \n",
    "for j in range(500, 997):\n",
    "    lines[j] = emojiCounts['mult'][j-500] + '\\n'\n",
    "    \n",
    "#Also add in words 'user' and 'multuser' to vocab file which will come up often\n",
    "#in tweets after preprocessing\n",
    "lines[997] = 'user '+ '\\n'\n",
    "lines[998] = 'multuser' + '\\n'\n",
    "    \n",
    "for j in range(500, 999):\n",
    "    lines[j] = emojiCounts['mult'][j-500] + '\\n'\n",
    "    \n",
    "with open('vocab1.txt', 'w', encoding = 'utf-8', errors = 'ignore') as f:\n",
    "    f.writelines(lines[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>We'll store this new vocab file in the GCS bucket containinig the pre-trained BERT model</b>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
